{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Count number of movies for every rating using the ml-100k u.data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#spark context is already running, so no need of broiler plate stuff\n",
    "\n",
    "#import file into an RDD, each line has form (movieid, userid, rating, epoch) separated by tab\n",
    "lines = sc.textFile(\"///C:/SparkCourse/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Unix time (also known as POSIX time or UNIX Epoch time) is a system for describing a point in time, defined as the number of seconds that have elapsed since 00:00:00 Coordinated Universal Time (UTC), Thursday, 1 January 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#split on tab and then convert the line row objects into key, value pairs RDD as (rating, movieid))\n",
    "linesSplit = lines.map(lambda lines: lines.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '50', '5', '881250949'], ['0', '172', '5', '881250949'], ['0', '133', '1', '881250949'], ['196', '242', '3', '881250949'], ['186', '302', '3', '891717742']]\n"
     ]
    }
   ],
   "source": [
    "print (linesSplit.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#define a python function to return the key value pairs (rating,1)\n",
    "def split_onTab(line):\n",
    "    line = line.split('\\t')\n",
    "    return (line[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#transform to RDD as (rating, 1)\n",
    "lineSplit = lines.map(lambda line: split_onTab(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('5', 1), ('5', 1), ('5', 1), ('5', 1), ('5', 1)]\n"
     ]
    }
   ],
   "source": [
    "print (lineSplit.top(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform to convert into RDD as (rating, count)\n",
    "ratingTotal = lineSplit.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[19] at RDD at PythonRDD.scala:48\n"
     ]
    }
   ],
   "source": [
    "print (ratingTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 34174), ('1', 6111), ('5', 21203), ('3', 27145), ('2', 11370)]\n"
     ]
    }
   ],
   "source": [
    "# Action to collect RDD into python object : to Return all the elements of the dataset RDD as an array at the driver program\n",
    "result = ratingTotal.collect()\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating \t count\n",
      "1 \t 6111\n",
      "2 \t 11370\n",
      "3 \t 27145\n",
      "4 \t 34174\n",
      "5 \t 21203\n"
     ]
    }
   ],
   "source": [
    "# loop over the python object\n",
    "print ('rating \\t count')\n",
    "for rating, count in sorted(result):\n",
    "    print (rating, '\\t', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Final Spark Program, which can be submitted to a 'local' Spark instance, set appropriate master to run on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating \t count\n",
      "1 \t 6111\n",
      "2 \t 11370\n",
      "3 \t 27145\n",
      "4 \t 34174\n",
      "5 \t 21203\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "### Count number of movies for every rating using the ml-100k u.data file\n",
    "###################################################################################\n",
    "\n",
    "#broiler plate stuff to be un commented\n",
    "####from pyspark import SparkConf, SparkContext\n",
    "\n",
    "####conf = SparkConf().SetMaster(\"local\").setAppName(\"MovieCountByRatings\")\n",
    "####sc = SparkContext(conf = conf)\n",
    "\n",
    "#import file into an RDD, each line has form (movieid, userid, rating, epoch) separated by tab\n",
    "lines = sc.textFile(\"///C:/SparkCourse/ml-100k/u.data\")\n",
    "\n",
    "#define a python function to return the key value pairs (rating,1)\n",
    "def split_onTab(line):\n",
    "    line = line.split('\\t')\n",
    "    return (line[2], 1)\n",
    "\n",
    "#transform to RDD as (rating, 1)\n",
    "lineSplit = lines.map(lambda line: split_onTab(line))\n",
    "\n",
    "# Transform to convert into RDD as (rating, count)\n",
    "ratingTotal = lineSplit.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Action to collect RDD into python object which is default dictionary\n",
    "result = ratingTotal.collect()\n",
    "\n",
    "# loop over the python object\n",
    "print ('rating \\t count')\n",
    "for rating, count in sorted(result):\n",
    "    print (rating, '\\t', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
